{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing and cleaning the data :\nFirst we start by importing the relevant libraries to be used\nat first i only imported pandas,randomforestclassifier and linear regression from sklearn but as i worked on i needed more functions like R2_score from sklearn and sns/matplot to visualize the data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom scipy.stats import linregress\nfrom prettytable import PrettyTable\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we import the data base that we will work on and inspect it to see if it needs cleaning.\nit seems that we are missing the columns so we will start by getting them from the kaggle database desciption\nour new columns are as follows :\nCRIM - per capita crime rate by town\n\nZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n\nINDUS - proportion of non-retail business acres per town.\n\n\nCHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n\n\nNOX - nitric oxides concentration (parts per 10 million)\n\n\nRM - average number of rooms per dwelling\n\n\nAGE - proportion of owner-occupied units built prior to 1940\n\n\nDIS - weighted distances to five Boston employment centres\n\n\nRAD - index of accessibility to radial highways\n\n\nTAX - full-value property-tax rate per $10,000\n\n\nPTRATIO - pupil-teacher ratio by town\n\n\nB - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n\n\nLSTAT - percentage of lower status of the population\n\n\nMEDV - Median value of owner-occupied homes in $1000's","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('housing.csv')\ndf.columns = ['CRIM','ZN', 'INDUS', 'CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\nprint(df.head(5))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have loaded the data and set our columns , now we will check if our data is missing any values that might make our random forest not work.\nrunning the function below shows that our data isn't missing any values.So let's do some visualization and then we can continue to the linear regression and random forest models.","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing the data :","metadata":{}},{"cell_type":"code","source":"# histogram of the target variable\nplt.hist(df['MEDV'])\nplt.xlabel('Median value of owner-occupied homes in $1000s')\nplt.ylabel('Frequency')\nplt.show()\n#correlation matrix\ncorr = df.corr()\nsns.heatmap(corr, cmap='coolwarm', annot=True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we can obeserve from the histograms of the target column that our data follows a slightly normal distribution with its median being at 200000 dollars\nat a frequency of 150 (ouf ot our sample dataset).\nfrom the correlation matrix we can observe strong corerlation between some of our features such as taxation and accessibility to radial highways\nand very weak correlation between some other features such as age and distance to employment centres. both observations seem logical.\nOur dataset seems logical and has no missing values, the data types seem to be consistent so we can move on to the linear regression\n# Linear Regression : \nFirst we will split our data into training and testing sets then we will train our model to predict the MEDV (median value of house prices) and finally we will evaluate its performance and try to visualize it.","metadata":{}},{"cell_type":"code","source":"#Making a copy of the dataset specific to the Linear Regression : \ndf_LR = df.copy()\n#Splitting the data into training set and testing set\nX = df_LR.drop('MEDV', axis=1)\ny = df_LR['MEDV']\nX_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.2, random_state=25)\n#Training the model \nlr = LinearRegression()\nlr.fit(X_train, y_train)\n#Evaluating \ny_pred = lr.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\nprint(f\"Linear Regression:\")\nprint(f\"Mean Squared Error: {mse:.2f}\")\nprint(f\"R-squared: {r2:.2f}\")\n#Visualizing the performance of the model \nplt.scatter(y_test, y_pred)\nplt.xlabel('Actual values')\nplt.ylabel('Predicted values')\nplt.title('Linear Regression: Actual vs Predicted values')\nslope, intercept, r_value, p_value, std_err = linregress(y_test, y_pred)\nline = slope * y_test + intercept\nplt.plot(y_test, line, color='red', label='Line of best fit')\n\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So the linear regression gives us the aforementioned results with a MSE of 20.56 and an R² of 0.75. Let's move to a random forest approach and compare their performance.\n# Random Forest : ","metadata":{}},{"cell_type":"code","source":"df_RF = df.copy()\n#We already split the dataset earlier so to ensure a fair comparison between both approaches we will maintain the same \n#training and testing sets\n#Training the random forest regressor and making prediction \nrf = RandomForestRegressor(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\n#Evaluating the model \nmserf = mean_squared_error(y_test, y_pred)\nr2rf = r2_score(y_test, y_pred)\nprint(f\"Random Forest Regression:\")\nprint(f\"Mean Squared Error: {mserf:.2f}\")\nprint(f\"R^2 Score: {r2rf:.2f}\")\n#Visualizing the performance of the model \nplt.scatter(y_test, y_pred)\nplt.xlabel('Actual values')\nplt.ylabel('Predicted values')\nplt.title('Random Forest Regression: Actual vs Predicted values')\nslope, intercept, r_value, p_value, std_err = linregress(y_test, y_pred)\nline = slope * y_test + intercept\nplt.plot(y_test, line, color='red', label='Line of best fit')\n\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"table = PrettyTable()\ntable.field_names = [\"Model\", \"MSE\", \"R²\"]\n\ntable.add_row([\"Random Forest Regression\", 12.25, 0.85])\ntable.add_row([\"Linear Regression\", 20.56, 0.75])\n\nprint(\"Comparison of models\\n\")\nprint(table)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion : \nA final comparison of the error scores and R² of both models shows that the random forest regression is more accurate in analyzing this dataset and predicting the house prices.\n\nwork done by : hamdi neffati BA.Ibe","metadata":{}}]}
